{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the packages needed\n",
    "import docx2txt\n",
    "import PyPDF2\n",
    "from PyPDF2 import PdfFileReader\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import seaborn as sns\n",
    "import string\n",
    "import plotly.express as px\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = docx2txt.process(\"Curriculum Vitae - Job 2.docx\") #read file\n",
    "cv2 = docx2txt.process(\"Nora's CV.docx\")\n",
    "cv3 = docx2txt.process(\"Amanda's CV.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the resume in a variable\n",
    "def process_resume (file):\n",
    "    import re #regular expression for editing text\n",
    "    import nltk #nltk library for hand\n",
    "    from textblob import TextBlob\n",
    "    from nltk.corpus import stopwords #to remove stopwords\n",
    "    from nltk.tokenize import word_tokenize #to split text into minimal meaningful units\n",
    "    from textblob import Word #to extract a root word by considering the vocabulary\n",
    "    from nltk.stem import PorterStemmer #to extract the root word of a text\n",
    "    \n",
    "    from nltk.util import ngrams  \n",
    "    \n",
    "    resume = file\n",
    "    \n",
    "    #convert to lowercase\n",
    "    resume = resume.lower()\n",
    "    \n",
    "    #remove hyphen\n",
    "    resume = resume.replace('_','')\n",
    "    \n",
    "    #remove punctuation\n",
    "    resume = re.sub(r'[^\\w\\s]','', resume) \n",
    "    \n",
    "    #Remove additional white spaces\n",
    "    resume = re.sub('[\\s]+', ' ', resume)\n",
    "    resume = re.sub('[\\n]+', ' ', resume)\n",
    "    \n",
    "    #Remove not alphanumeric symbols white spaces\n",
    "    resume = re.sub(r'[^\\w]', ' ', resume)\n",
    "    \n",
    "    #extract email address\n",
    "    addresses = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', resume)\n",
    "    \n",
    "    #correct wrong spelling\n",
    "    #resume = ''.join(str(TextBlob(resume).correct()))\n",
    "    \n",
    "    #lemmatize text    \n",
    "    resume = \" \".join([Word(word).lemmatize() for word in resume.split()])\n",
    "    \n",
    "    #tokenize text\n",
    "    resume = nltk.word_tokenize(resume)\n",
    "    \n",
    "    #remove stopwords\n",
    "    stop = stopwords.words('english')\n",
    "    resume = [i for i in resume if not i in stop]\n",
    "    \n",
    "    #stemming\n",
    "    #stemmer = PorterStemmer()\n",
    "    #resume=\" \".join([stemmer.stem(word) for word in resume.split()]))\n",
    "    \n",
    "    #trim\n",
    "    #resume = resume.strip('\\'\"')\n",
    "    \n",
    "    resume = \" \".join(resume)\n",
    "        \n",
    "    file = resume\n",
    "    \n",
    "    return file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['israel ilori data scientist ogenepabogmailcom linkedin israel ilori github israelilori skill machine learning tool scikitlearn tensorflow kera numpy panda matplotlib spacy nltk gensim programming python r sql c netcore data analytics tool tableau powerbi software tool jupyter lab mysql workbench mongodb docker visual studio code aws office education university manchester sep 2018 sep 2019 msc data science w computer science data informatics merit thesis detection bot social medium using supervised machine learning naïve bayes random forest module statistic machine learning understanding database applied data science joseph ayo babalola university oct 2011 aug 2015 bsc computer science 21 thesis developed web inventory management system php cs html javascript graduated top 5 class early height college aug 2008 july 2011 high school award 5 distinction 2 credit school best student waec mathematics 2011 president committee student data science project fcmb trustee web api augsept 2020 client project na intellectual property fcmb trustee built web api expose internal trust system mobile web client leveraged aspnet core 3 swagger entity framework core implement required functionality detection bot social medium sep 2019 master thesis link developed framework detect bot social medium created etl pipeline extract data twitter reddit using python trained retrained bot detection model train validation set evaluated test set outcome project achieved 65 merit grade embedding uk business using diverse data june 2019 group project client project na intellectual property peak ai worked team 4 develop rulebased nlp recommendation tool identifies uk company run similar business contributed creating etl pipeline scrape company data linkedin twitter financial time company house using python trained implemented word2vec model text data identify similar business outcome project wa carried manchesterbased ai company incorporate pipeline competitive analysis existing prospective client customer transaction classification apr 2019 personal project link built efficient neural network using data provided kaggle predict customer likely make specific transaction future trained model performed hyperparameter tuning outcome posttraining convergence wa reached 10 epoch validation data model wa applied test data achieved 89 evaluation accuracy work experience bright network uk jul 2020 internship experience standard bank stanbic ibtc aug 2017 aug 2018 analyst haybeecrown limited oct 2016 aug 2017 technology supervisor digital bridge institute dec 2015 oct 2016 technology associate city business computer emea june 2014 jul 2014 intern award certification wes credential evaluation bright network uk internship certificate extracurricular activity hope chapel manchester oct 2018 oct 2019 president youthstudent association led association raise 500 charitable cause coached youth team victory friendly match hobby sport volunteer gym trainer engage tennis single double local tennis club play video game']\n"
     ]
    }
   ],
   "source": [
    "#call the function with your data\n",
    "processed_resume1 = [process_resume(cv1)]\n",
    "print (processed_resume1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nora chinwendu nnabuihe bsc aca nnabuihechinwenduyahoocom linkedin nora nnabuihe 08033018672 profile resultdriven analytical ambitious professional diversiﬁed skillset knowledge accounting auditing operation three year work experience willingness improve capacity seek work reputable organization skill utilized towards proﬁtability skill core competency sage excellent communication quickbooks teamwork microsoft excel advanced detail oriented eskadenia data analysis microsoft powerpoint microsoft word negotiation research trainingscertifications association chartered accountant aca institute chartered accountant nigeria ican 2020 education bsc ed accounting education 2014 university benin benin city edo state senior school certiﬁcate examination oakland comprehensive college okota lagos 2009 experience accountant sovereign trust insurance plc head oﬃce victoria island lagos dec 2016 present duty achievement collaborate government tax auditor state federal level providing accurate information tax year audit deliver tax report ensure various tax withholding value added tax remitted due prepare report company expense detailed breakdown showing monthly quarterly yearly analysis calculate monthly pension deduction pay earn paye utilizing sage software boosting accuracy 90 consistently meet company turnaround time processing daily transaction increasing output enhancing proﬁtability drafted prepared journal entry bank reconciliation account receivables budget promptly prepare petty cash reconciliation utilizing microsoft excel strictly comply relevant internal external insurance operation policiesregulations review bank activity guarantee proper payment credited correct account appropriate amount debited preparation proﬁtability report branch quarterly preparation submission national insurance commission naicom report quarterly accountant intern sovereign trust insurance plc wuse abuja nysc dec 2015 sep 2016 duty achievement gained ﬁrsthand practical experience accounting operation worked team professional eﬃciently processed receipt premium paid client beating turnaround time improving overall work output performed weekly monthly yearly account reconciliation upon requested superior reference available request']\n"
     ]
    }
   ],
   "source": [
    "#call the function with your data\n",
    "processed_resume2 = [process_resume(cv2)]\n",
    "print (processed_resume2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amanda sopuruchi emerson amandaemersonsopuruchigmailcom 08137055190 linkedin emerson amanda career summary recent graduate first class honour king university time university developed excellent timemanagement organisational skill due series closeknit coursework deadline exam result incredibly adaptable able work pressure effectively business analyst proven track record conducting research analysis deliver datadriven recommendation stakeholder education king university osun nigeria bsc biochemistry first class 2015 2019 university best graduating student 2019 biochemistry department best graduating student 2019 professional experience delta state contributory health commission business analyst department business development marketing dec 2019 till date collect organizes analysis data generates provides accurate complete report management andor regulatory agency assist developing strategy ensure system project meet business objective requirement work closely client support development successful implementation innovative high quality business solution perform lead various analysis interpretation link business need objective assigned function implement process improvement lead support business initiative data analysis identification implementation barrier user acceptance testing various system develop share incorporate organizational best practice business application responsible ensuring timely update enrollsee information provided accredited healthcare facility responsible managing communication accredited service provider responsible evaluating reviewing interpreting implementing procedure providing recommendation appropriate level existing potential client pladis global ap food ltd laboratory analyst quality assurance technologist february august 2018 worked microbiology analytical chemistry laboratory improving la technique standard operating procedure time efficiency management updated product quality plan reflect important testing customer demand worked collaboratively manufacturing department enforce safety quality assurance protocol safe food manufacturing assisted toolbox teambuilding exercise boost morale increase teamwork conducted independent quality audit production process equipment environment product monitored compliance implementation sop cgmp environment health safety requirement line daily calibration maintenance laboratory equipment support credibility result ensured effective inprocess quality check manufacturing packaging process achieve product quality key competency skill excellent knowledge business process automation workflow concept instrument superior proficiency office including powerpoint excel word strong problemsolving analytical ability exceptional evaluation judgment skill high oral written communication skill data analysis learning agility hobby writing travelling learning new skill reference available request']\n"
     ]
    }
   ],
   "source": [
    "#call the function with your data\n",
    "processed_resume3 = [process_resume(cv3)]\n",
    "print (processed_resume3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data scientist responsibility include undertaking data collection preprocessing analysis building model address business problem presenting information using data visualization technique job brief looking data scientist analyze large amount raw information find pattern help improve company rely build data product extract valuable business insight role highly analytical knack analysis math statistic critical thinking problemsolving skill essential interpreting data also want see passion machinelearning research goal help company analyze trend make better decision responsibility identify valuable data source automate collection process undertake preprocessing structured unstructured data analyze large amount information discover trend pattern build predictive model machinelearning algorithm combine model ensemble modeling present information using data visualization technique propose solution strategy business challenge collaborate engineering product development team requirement proven experience data scientist data analyst experience data mining understanding machinelearning operation research knowledge r sql python familiarity scala java c asset experience using business intelligence tool eg tableau data framework eg hadoop analytical mind business acumen strong math skill eg statistic algebra problemsolving aptitude excellent communication presentation skill bscba computer science engineering relevant field graduate degree data science quantitative field preferred']\n"
     ]
    }
   ],
   "source": [
    "jd = docx2txt.process(\"Job Description.docx\")\n",
    "\n",
    "processed_jd = [process_resume(jd)]\n",
    "\n",
    "print (processed_jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#documents = [processed_resume1, processed_jd]\n",
    "#print (documents)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Find similarities using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix1 = tfidf_vectorizer.fit_transform(processed_jd)\n",
    "\n",
    "tfidf_matrix2 = tfidf_vectorizer.transform(processed_resume1)\n",
    "tfidf_matrix3 = tfidf_vectorizer.transform(processed_resume2)\n",
    "tfidf_matrix4 = tfidf_vectorizer.transform(processed_resume3)\n",
    "#tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity Scores:\n",
      "Your resume matches about 71.64% of the job description.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSimilarity Scores:\")\n",
    "\n",
    "#convert to percentage\n",
    "matchPercentage = cosine_similarity(tfidf_matrix1, tfidf_matrix2) * 100\n",
    "matchPercentage = np.round(matchPercentage, 2) # round to two decimal\n",
    "print(\"Your resume matches about \"+ str(matchPercentage[0][0])+ \"% of the job description.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity Scores:\n",
      "Your resume matches about 40.16% of the job description.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSimilarity Scores:\")\n",
    "\n",
    "#convert to percentage\n",
    "matchPercentage2 = cosine_similarity(tfidf_matrix1, tfidf_matrix3) * 100\n",
    "matchPercentage2 = np.round(matchPercentage2, 2) # round to two decimal\n",
    "print(\"Your resume matches about \"+ str(matchPercentage2[0][0])+ \"% of the job description.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity Scores:\n",
      "Your resume matches about 49.67% of the job description.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSimilarity Scores:\")\n",
    "\n",
    "#convert to percentage\n",
    "matchPercentage3 = cosine_similarity(tfidf_matrix1, tfidf_matrix4) * 100\n",
    "matchPercentage3 = np.round(matchPercentage3, 2) # round to two decimal\n",
    "print(\"Your resume matches about \"+ str(matchPercentage3[0][0])+ \"% of the job description.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pickle the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#print(pickle.__doc__)\n",
    "pickle.dump(tfidf_vectorizer, open('tfidf_vectorizer.pkl', 'wb'))\n",
    "#outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
